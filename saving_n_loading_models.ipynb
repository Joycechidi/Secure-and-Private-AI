{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "saving_n_loading_models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joycechidi/Secure-and-Private-AI/blob/master/saving_n_loading_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEWIBCmDf1fY",
        "colab_type": "text"
      },
      "source": [
        "# Saving and Loading Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqJR_azbflgR",
        "colab_type": "code",
        "outputId": "cf7ec516-d51e-4e77-d83e-5c902d5883d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "!wget https://github.com/udacity/deep-learning-v2-pytorch/raw/master/intro-to-pytorch/helper.py\n",
        "!wget https://github.com/udacity/deep-learning-v2-pytorch/raw/master/intro-to-pytorch/fc_model.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-12 04:50:02--  https://github.com/udacity/deep-learning-v2-pytorch/raw/master/intro-to-pytorch/helper.py\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py [following]\n",
            "--2019-06-12 04:50:03--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2813 (2.7K) [text/plain]\n",
            "Saving to: ‘helper.py.2’\n",
            "\n",
            "helper.py.2         100%[===================>]   2.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-12 04:50:03 (49.8 MB/s) - ‘helper.py.2’ saved [2813/2813]\n",
            "\n",
            "--2019-06-12 04:50:03--  https://github.com/udacity/deep-learning-v2-pytorch/raw/master/intro-to-pytorch/fc_model.py\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/fc_model.py [following]\n",
            "--2019-06-12 04:50:04--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/fc_model.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3543 (3.5K) [text/plain]\n",
            "Saving to: ‘fc_model.py.2’\n",
            "\n",
            "fc_model.py.2       100%[===================>]   3.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-12 04:50:04 (69.6 MB/s) - ‘fc_model.py.2’ saved [3543/3543]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tDP-hOPgDeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import helper\n",
        "import fc_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJPDx0q1gEBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og4itjt0gEDw",
        "colab_type": "code",
        "outputId": "04c66873-204c-4046-adc9-a14a74623d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "#Let's view one image\n",
        "image, label = next(iter(trainloader))\n",
        "helper.imshow(image[0,:]);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAAHTCAYAAAB8/vKtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYgoAkZgCQCSmABCJKQBEYgoAkZgCQPS/9dlN1MwBtWIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 233,
              "height": 233
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNGFTRlAgt8C",
        "colab_type": "text"
      },
      "source": [
        "# Train a Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhTQw4OvgEGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the network, define the criterion and optimizer\n",
        "# input_neurons = 784\n",
        "# output_neurons = 10  #output layer here is log softmax\n",
        "# 3 hidden_layers\n",
        "# h1 = 512\n",
        "# h2 = 256\n",
        "# h3 = 128\n",
        "\n",
        "model = fc_model.Network(784, 10, [512, 256, 128])\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbIgyPVzgEIy",
        "colab_type": "code",
        "outputId": "481b2f02-6bd1-4659-c3c2-211ee3bb7247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "\n",
        "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/2..  Training Loss: 1.699..  Test Loss: 0.991..  Test Accuracy: 0.596\n",
            "Epoch: 1/2..  Training Loss: 1.049..  Test Loss: 0.730..  Test Accuracy: 0.727\n",
            "Epoch: 1/2..  Training Loss: 0.846..  Test Loss: 0.688..  Test Accuracy: 0.743\n",
            "Epoch: 1/2..  Training Loss: 0.748..  Test Loss: 0.649..  Test Accuracy: 0.755\n",
            "Epoch: 1/2..  Training Loss: 0.748..  Test Loss: 0.615..  Test Accuracy: 0.770\n",
            "Epoch: 1/2..  Training Loss: 0.743..  Test Loss: 0.601..  Test Accuracy: 0.768\n",
            "Epoch: 1/2..  Training Loss: 0.699..  Test Loss: 0.605..  Test Accuracy: 0.769\n",
            "Epoch: 1/2..  Training Loss: 0.691..  Test Loss: 0.577..  Test Accuracy: 0.787\n",
            "Epoch: 1/2..  Training Loss: 0.714..  Test Loss: 0.560..  Test Accuracy: 0.790\n",
            "Epoch: 1/2..  Training Loss: 0.697..  Test Loss: 0.542..  Test Accuracy: 0.802\n",
            "Epoch: 1/2..  Training Loss: 0.619..  Test Loss: 0.554..  Test Accuracy: 0.799\n",
            "Epoch: 1/2..  Training Loss: 0.632..  Test Loss: 0.540..  Test Accuracy: 0.800\n",
            "Epoch: 1/2..  Training Loss: 0.632..  Test Loss: 0.523..  Test Accuracy: 0.814\n",
            "Epoch: 1/2..  Training Loss: 0.601..  Test Loss: 0.515..  Test Accuracy: 0.819\n",
            "Epoch: 1/2..  Training Loss: 0.596..  Test Loss: 0.514..  Test Accuracy: 0.814\n",
            "Epoch: 1/2..  Training Loss: 0.575..  Test Loss: 0.497..  Test Accuracy: 0.813\n",
            "Epoch: 1/2..  Training Loss: 0.566..  Test Loss: 0.522..  Test Accuracy: 0.804\n",
            "Epoch: 1/2..  Training Loss: 0.598..  Test Loss: 0.502..  Test Accuracy: 0.817\n",
            "Epoch: 1/2..  Training Loss: 0.604..  Test Loss: 0.494..  Test Accuracy: 0.823\n",
            "Epoch: 1/2..  Training Loss: 0.589..  Test Loss: 0.512..  Test Accuracy: 0.816\n",
            "Epoch: 1/2..  Training Loss: 0.594..  Test Loss: 0.478..  Test Accuracy: 0.826\n",
            "Epoch: 1/2..  Training Loss: 0.571..  Test Loss: 0.474..  Test Accuracy: 0.826\n",
            "Epoch: 1/2..  Training Loss: 0.568..  Test Loss: 0.489..  Test Accuracy: 0.823\n",
            "Epoch: 2/2..  Training Loss: 0.558..  Test Loss: 0.479..  Test Accuracy: 0.817\n",
            "Epoch: 2/2..  Training Loss: 0.536..  Test Loss: 0.479..  Test Accuracy: 0.822\n",
            "Epoch: 2/2..  Training Loss: 0.531..  Test Loss: 0.472..  Test Accuracy: 0.826\n",
            "Epoch: 2/2..  Training Loss: 0.552..  Test Loss: 0.479..  Test Accuracy: 0.823\n",
            "Epoch: 2/2..  Training Loss: 0.581..  Test Loss: 0.477..  Test Accuracy: 0.829\n",
            "Epoch: 2/2..  Training Loss: 0.528..  Test Loss: 0.467..  Test Accuracy: 0.825\n",
            "Epoch: 2/2..  Training Loss: 0.541..  Test Loss: 0.476..  Test Accuracy: 0.824\n",
            "Epoch: 2/2..  Training Loss: 0.575..  Test Loss: 0.459..  Test Accuracy: 0.825\n",
            "Epoch: 2/2..  Training Loss: 0.501..  Test Loss: 0.485..  Test Accuracy: 0.830\n",
            "Epoch: 2/2..  Training Loss: 0.584..  Test Loss: 0.476..  Test Accuracy: 0.820\n",
            "Epoch: 2/2..  Training Loss: 0.501..  Test Loss: 0.459..  Test Accuracy: 0.828\n",
            "Epoch: 2/2..  Training Loss: 0.536..  Test Loss: 0.455..  Test Accuracy: 0.833\n",
            "Epoch: 2/2..  Training Loss: 0.537..  Test Loss: 0.455..  Test Accuracy: 0.832\n",
            "Epoch: 2/2..  Training Loss: 0.521..  Test Loss: 0.467..  Test Accuracy: 0.832\n",
            "Epoch: 2/2..  Training Loss: 0.500..  Test Loss: 0.459..  Test Accuracy: 0.830\n",
            "Epoch: 2/2..  Training Loss: 0.494..  Test Loss: 0.458..  Test Accuracy: 0.827\n",
            "Epoch: 2/2..  Training Loss: 0.521..  Test Loss: 0.445..  Test Accuracy: 0.834\n",
            "Epoch: 2/2..  Training Loss: 0.507..  Test Loss: 0.446..  Test Accuracy: 0.831\n",
            "Epoch: 2/2..  Training Loss: 0.492..  Test Loss: 0.456..  Test Accuracy: 0.835\n",
            "Epoch: 2/2..  Training Loss: 0.505..  Test Loss: 0.459..  Test Accuracy: 0.837\n",
            "Epoch: 2/2..  Training Loss: 0.562..  Test Loss: 0.473..  Test Accuracy: 0.826\n",
            "Epoch: 2/2..  Training Loss: 0.542..  Test Loss: 0.458..  Test Accuracy: 0.830\n",
            "Epoch: 2/2..  Training Loss: 0.514..  Test Loss: 0.448..  Test Accuracy: 0.838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7GkcPw1imMJ",
        "colab_type": "text"
      },
      "source": [
        "# Saving and loading networks\n",
        "\n",
        "it's impractical to train a network every time you need to use it. Instead, we can save trained networks then load them later to train more or use them for predictions.\n",
        "\n",
        "The parameters for PyTorch networks are stored in a model's state_dict. We can see the state dict contains the weight and bias matrices for each of our layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq-ffrwzgELG",
        "colab_type": "code",
        "outputId": "5be714b7-1583-4739-8d63-571bce71a7c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "print(\"Our model: \\n\\n\", model, '\\n')\n",
        "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our model: \n",
            "\n",
            " Network(\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  )\n",
            "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5)\n",
            ") \n",
            "\n",
            "The state dict keys: \n",
            "\n",
            " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U8JCYKMjEBI",
        "colab_type": "text"
      },
      "source": [
        "The simplest thing to do is simply save the state dict with torch.save. For example, we can save it to a file 'checkpoint.pth'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XTw0DOPgENh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#I'll rebuild the model exactly how it was when being trained to eliminate size mismatch\n",
        "#The information about the model architecture needs to be saved in the \n",
        "#checkpoint along with the state dict.\n",
        "\n",
        "#To do this, I will build a dictionary with all the information needed to completely\n",
        "#rebuild the model. \n",
        "\n",
        "checkpoint = {'input_size': 784,\n",
        "             'output_size':10,\n",
        "             'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
        "             'state_dict': model.state_dict()}\n",
        "\n",
        "\n",
        "\n",
        "torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q3pV2H6E2tq",
        "colab_type": "text"
      },
      "source": [
        "The checkpoint now has all the necessary information to rebuild the the trained model.\n",
        "I'll make that a function. Then another function to load the checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s2zHsMSFMT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "  checkpoint = torch.load(filepath)\n",
        "  model = fc_model.Network(checkpoint['input_size'],\n",
        "                          checkpoint['output_size'],\n",
        "                          checkpoint['hidden_layers'])\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4xaNL9tGQbV",
        "colab_type": "code",
        "outputId": "29df10b5-8e72-4811-fb02-ea5f06f5a998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model = load_checkpoint('checkpoint.pth')\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  )\n",
            "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meP8RYyyHxoa",
        "colab_type": "text"
      },
      "source": [
        "We can load the statewith torch.load. And to load the state dict in to the network, you do model.load_state_dict(state_dict)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u45EzTl2t9ze",
        "colab_type": "code",
        "outputId": "253ea112-b1d9-4d36-ca7e-893bb665ad10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# #state_dict = torch.load('checkpoint.pth')\n",
        "# print(state_dict.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['input_size', 'output_size', 'hidden_layers', 'state_dict'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqPqW0NEjWdB",
        "colab_type": "text"
      },
      "source": [
        "Seems pretty straightforward, but as usual it's a bit more complicated. Loading the state dict works only if the model architecture is exactly the same as the checkpoint architecture. If I create a model with a different architecture, this fails"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P16VbaVBjPBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Try this\n",
        "# model = fc_model.Network(784, 10, [400, 200, 100])\n",
        "# # This will throw an error because the tensor sizes are wrong!\n",
        "# model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKTUKl5gjd0a",
        "colab_type": "text"
      },
      "source": [
        "This means we need to rebuild the model exactly as it was when trained. Information about the model architecture needs to be saved in the checkpoint, along with the state dict. To do this, you build a dictionary with all the information you need to compeletely rebuild the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XfOD8RqjPD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checkpoint = {'input_size': 784,\n",
        "#               'output_size': 10,\n",
        "#               'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
        "#               'state_dict': model.state_dict()}\n",
        "\n",
        "# torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evXRqeyFjPGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz9xkvJxjPI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz7Yixh4jPNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYlyqJK6jPQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k99Va1IhjPWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9mWwHKCjPML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}