{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handwritten_digits_identification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joycechidi/Secure-and-Private-AI/blob/master/handwritten_digits_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SedT8ygWqRyV",
        "colab_type": "code",
        "outputId": "1280858d-fbfd-44cd-e898-b543f169635e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!wget https://github.com/udacity/deep-learning-v2-pytorch/raw/master/intro-to-pytorch/helper.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-04 01:33:33--  https://github.com/udacity/deep-learning-v2-pytorch/raw/master/intro-to-pytorch/helper.py\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py [following]\n",
            "--2019-07-04 01:33:33--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2813 (2.7K) [text/plain]\n",
            "Saving to: ‘helper.py.1’\n",
            "\n",
            "helper.py.1         100%[===================>]   2.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-04 01:33:33 (41.6 MB/s) - ‘helper.py.1’ saved [2813/2813]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOr2AMziHFRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import necessary packaages\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEzFiJHLHFRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import helper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvv8FQ1jHFRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5,), (0.5,), (0.5,)),\n",
        "                               ])\n",
        "\n",
        "# #Download and load the training data\n",
        "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9iU2dHWObhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for image, label in trainloader:\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F86Stx31K7qm",
        "colab_type": "code",
        "outputId": "18cccc41-05a4-4a28-9f1c-bfbb1fc99d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh2U1EipLB4z",
        "colab_type": "code",
        "outputId": "9364290b-7e4c-486b-ed8e-1fb1e4e44a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def activation(x):\n",
        "    return 1/(1+torch.exp(-x))    #Sigmoid activation function\n",
        "\n",
        "#Flatten the input imges. Chooses the appropriate size for the number of elements\n",
        "inputs = images.view(images.shape[0], -1)\n",
        "n_input = 784\n",
        "n_hidden = 256\n",
        "n_output = 10\n",
        "\n",
        "#Create parameters\n",
        "\n",
        "W1 = torch.randn(n_input, n_hidden)\n",
        "B1 = torch.randn(n_hidden)\n",
        "\n",
        "#Weights for inputs to hidden layer\n",
        "W2 = torch.randn(n_hidden, n_output)\n",
        "B2 = torch.randn(n_output)\n",
        "\n",
        "h = activation(torch.mm(inputs, W1) + B1)\n",
        "\n",
        "output = torch.mm(h, W2) + B2\n",
        "\n",
        "print(output.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im8XlZbeRcsg",
        "colab_type": "code",
        "outputId": "c14f277a-253f-48a3-ad55-489b8606a170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 2.3972e+00,  1.3427e+01, -6.6107e+00,  9.5487e+00, -7.1117e+00,\n",
            "         -5.2640e+00, -7.9234e+00,  3.2493e+00,  4.8567e+00,  3.3421e+00],\n",
            "        [-1.5212e+00,  1.5947e+00, -1.2279e+01,  9.5108e+00,  2.0851e+00,\n",
            "         -4.2515e+00, -1.0986e-01,  1.6105e+01,  1.3594e+00,  7.6460e-01],\n",
            "        [ 7.2615e+00,  1.1990e+01, -2.2577e+01,  2.1061e+01,  2.9824e+00,\n",
            "         -3.3917e+00, -2.0667e+00,  1.0773e+01,  8.0101e+00,  1.1416e+00],\n",
            "        [-7.7161e-01,  1.1887e+01, -1.3216e+01,  2.3681e+01,  3.5582e+00,\n",
            "         -1.3777e+00, -9.9416e+00,  1.7063e+01,  1.2542e+01,  8.8278e-01],\n",
            "        [ 7.1930e-01,  5.6023e+00, -2.1244e-01,  1.8990e+01,  1.4171e+00,\n",
            "         -1.2687e+01, -7.9640e-01,  1.8669e+01,  6.5251e+00,  1.8570e+00],\n",
            "        [-9.9923e-01,  3.2474e+00, -7.5639e+00,  2.1117e+01,  3.5643e+00,\n",
            "         -1.0359e+01, -2.4891e+00,  1.0004e+01,  6.3324e+00, -3.9626e+00],\n",
            "        [ 1.1020e+00,  7.6313e+00, -6.1607e+00,  1.3559e+01,  7.9078e+00,\n",
            "         -1.0163e+01, -8.0285e+00,  1.4056e+01,  8.6406e+00,  1.0398e-02],\n",
            "        [-1.6123e+00,  8.5059e+00, -1.6771e+01,  1.2145e+01,  6.9588e+00,\n",
            "         -1.7844e+00, -2.7468e-01,  7.8102e+00,  1.6765e+01,  4.4575e+00],\n",
            "        [ 3.2044e+00,  2.2200e+00, -1.2088e+01,  1.8104e+01, -2.2975e+00,\n",
            "          8.3372e+00, -1.4220e+00,  4.0265e+00,  2.9940e+00, -3.7512e+00],\n",
            "        [ 7.5893e+00, -2.3585e+00, -7.0376e+00,  7.4218e+00,  9.0525e-01,\n",
            "         -9.5543e+00, -6.3834e+00,  2.2365e+01,  1.5301e+00,  1.2666e+00],\n",
            "        [-2.9858e+00,  1.2261e+00, -1.8005e+01, -8.1929e-01,  5.6511e+00,\n",
            "         -1.5720e+01,  8.1747e+00,  4.7901e+00,  5.4263e+00, -9.6881e+00],\n",
            "        [-4.0904e+00,  1.8113e+00, -6.2429e+00,  1.6444e+01,  4.6470e+00,\n",
            "         -1.0812e+01,  5.7293e+00,  3.6006e+00,  3.6637e+00, -1.0922e+00],\n",
            "        [ 1.2636e+00,  4.8077e+00, -1.2163e+01,  1.4738e+01,  3.5680e+00,\n",
            "         -1.7151e+01, -4.6368e+00,  7.5192e+00,  9.3290e+00,  5.0290e+00],\n",
            "        [ 3.5360e+00,  1.0470e+01, -1.0568e+01,  1.5596e+01,  1.4624e+01,\n",
            "         -1.1094e+00, -5.5590e-01,  1.0738e+01, -9.9570e-01, -2.4619e+00],\n",
            "        [-1.0217e+01,  1.3524e+00, -4.1023e+00,  2.1801e+01,  1.2325e+01,\n",
            "         -2.2264e+01, -1.7705e+00,  1.5384e+01,  6.5232e+00, -1.0146e+01],\n",
            "        [ 5.4423e+00,  1.3537e+01, -4.0302e+00,  1.3047e+01,  5.7692e+00,\n",
            "         -1.0864e+01, -1.0041e+01,  9.7167e+00,  4.9653e+00,  4.8107e+00],\n",
            "        [-5.7505e+00,  2.8142e+00, -2.0409e+01,  1.1894e+01,  1.4549e+01,\n",
            "         -5.3560e+00,  9.5663e+00,  9.3972e+00,  7.8364e-01, -8.3985e+00],\n",
            "        [-1.4334e+00,  5.9537e+00, -1.4608e+01,  9.8682e+00,  1.7851e+00,\n",
            "         -8.6151e+00, -9.4914e+00,  1.4840e+01,  4.5153e+00,  1.0101e+00],\n",
            "        [-5.5374e+00, -2.5987e+00, -8.3783e+00,  2.5619e+01,  1.1663e+00,\n",
            "         -6.2484e+00, -8.7026e+00,  1.0677e+01,  1.3468e+01,  6.1990e+00],\n",
            "        [ 2.6451e+00,  1.1955e+00, -1.0027e+01,  1.3859e+01,  1.6054e-01,\n",
            "         -3.0508e+00, -5.7199e+00,  1.1929e+01,  1.0257e+01,  2.2459e+00],\n",
            "        [ 1.3413e+00,  1.0652e+00,  5.2355e+00,  8.9408e+00,  3.7241e+00,\n",
            "         -1.0017e+01,  1.8480e+00,  1.7528e+01,  6.9538e+00,  3.3755e+00],\n",
            "        [ 9.8281e-01, -4.8312e+00, -1.5849e+01,  3.7398e+00,  1.3680e+01,\n",
            "         -1.1744e+01, -2.8043e+00,  2.1676e+01,  5.2791e+00, -3.3845e+00],\n",
            "        [-7.0251e+00,  8.7225e+00, -6.0728e+00,  2.4584e+01,  7.0459e+00,\n",
            "         -1.0855e+01, -9.5909e+00,  1.0489e+01,  1.8855e+01,  4.5581e+00],\n",
            "        [ 9.7707e-01,  1.1634e+01, -1.3576e+01,  1.5066e+01,  9.0997e+00,\n",
            "         -1.2517e+01, -1.2522e+01,  1.6054e+01, -4.5882e-01, -3.3549e+00],\n",
            "        [ 6.1724e-01, -3.7192e+00, -5.1513e+00,  1.6740e+01,  6.2885e-02,\n",
            "         -1.4478e+01, -8.9674e+00,  1.3073e+01,  8.6927e+00,  3.3779e+00],\n",
            "        [ 1.8862e-01,  7.7656e-01, -1.0791e+01,  1.2202e+01,  6.1350e+00,\n",
            "         -1.1990e+01,  2.2884e+00,  1.1040e+01, -1.3139e-01, -3.6394e+00],\n",
            "        [ 3.4942e+00,  1.0363e+01, -1.0131e+01,  2.3948e+01,  5.2753e+00,\n",
            "         -1.0028e+01, -6.0161e+00,  1.8854e+01,  8.8464e+00, -3.3124e+00],\n",
            "        [ 3.2657e+00, -1.7843e+00, -1.2568e+01,  1.8529e+01,  4.6422e+00,\n",
            "         -1.0009e+01, -1.5641e+00,  1.7252e+01,  1.0214e+01,  3.0470e+00],\n",
            "        [ 7.7245e+00,  5.9286e+00, -7.5944e+00,  1.1780e+01,  5.7862e+00,\n",
            "         -3.8643e+00, -4.6112e+00,  2.2440e+01,  8.5334e-02, -7.9468e+00],\n",
            "        [ 2.7256e+00,  6.4038e+00, -1.6187e+01,  1.9088e+01,  9.4633e+00,\n",
            "         -1.4878e+01,  1.8340e-01,  6.8282e+00,  7.4277e+00,  4.0192e+00],\n",
            "        [-5.1571e+00,  6.2774e+00, -9.3962e+00,  8.4178e+00,  1.0047e+01,\n",
            "         -4.5617e+00, -4.4668e+00,  7.7638e+00,  1.6443e+01, -2.1429e-02],\n",
            "        [ 6.1487e-01,  3.6073e+00, -1.3586e+01,  1.4983e+01,  9.0763e+00,\n",
            "         -3.9406e+00,  1.2533e+00,  9.8023e+00,  2.5195e+00,  3.4563e+00],\n",
            "        [-6.8035e+00, -2.2595e+00, -3.6554e+00,  1.4783e+01,  5.0050e+00,\n",
            "         -1.0205e+01, -3.3765e+00,  1.8799e+01,  1.0186e+01,  3.9043e+00],\n",
            "        [ 8.6579e+00,  2.9073e+00, -1.5550e+01,  1.8553e+01, -2.7584e+00,\n",
            "         -7.7791e+00, -2.7086e+00,  1.1302e+01,  2.2511e+00,  1.8672e+00],\n",
            "        [-7.3836e+00, -3.4616e-01, -1.3204e+00,  2.1268e+01,  1.2818e+01,\n",
            "         -3.4036e+00, -1.3487e+01,  2.4973e+01,  8.3549e+00, -8.6687e+00],\n",
            "        [-6.0899e+00,  6.8572e+00, -1.1544e+01,  2.1074e+01, -7.4832e-01,\n",
            "         -1.4094e+01,  1.4137e+00,  3.6705e+00,  6.1472e+00,  1.1499e+00],\n",
            "        [ 2.1064e+00,  1.0866e+00, -1.6385e+01,  9.6851e+00,  6.5024e+00,\n",
            "         -3.8308e+00,  2.3510e+00,  1.0370e+01, -3.3795e+00,  9.7834e-01],\n",
            "        [-1.2517e+01,  5.5572e+00, -1.3688e+01,  1.7145e+01,  1.1290e+01,\n",
            "         -1.6512e+01, -2.4756e+00,  1.5115e+01, -2.9262e+00, -9.8671e-01],\n",
            "        [ 3.4977e+00,  7.4380e+00, -1.3256e+01,  1.6281e+01,  1.0963e+01,\n",
            "         -2.9711e+00, -9.9186e+00,  1.6222e+01,  1.3443e+01, -2.2175e+00],\n",
            "        [-1.9092e+00, -1.9861e-01, -7.9992e+00,  1.2499e+01,  1.1075e-01,\n",
            "         -4.3306e+00, -7.4688e+00,  1.4690e+01,  6.4136e+00,  3.3127e+00],\n",
            "        [ 2.1854e+00,  1.7169e+01, -1.4382e+01,  8.0172e+00,  9.4000e+00,\n",
            "         -6.8759e+00, -1.8305e+00, -1.4269e+00,  1.0617e+01, -4.9946e+00],\n",
            "        [ 2.9530e+00, -1.0060e+00, -1.6784e+01,  1.9431e+01,  4.4708e+00,\n",
            "         -5.8306e+00, -1.3976e+01,  3.1902e+00, -2.7435e+00, -2.8526e+00],\n",
            "        [ 5.1338e+00,  1.1965e+01, -3.0990e+01,  1.8074e+01,  7.2850e+00,\n",
            "         -6.3939e-02, -6.6458e+00,  1.0229e+01,  8.0103e+00, -3.8040e-01],\n",
            "        [ 5.4050e+00,  1.1684e+01, -1.4676e+01,  8.9277e+00,  2.9778e+00,\n",
            "         -7.9104e+00,  1.8205e+00,  1.2717e+01,  8.8399e+00, -1.2965e+01],\n",
            "        [ 7.1495e+00,  3.4194e+00, -1.3835e+01,  2.0381e+01,  1.0720e+01,\n",
            "         -2.3819e+00, -1.2084e+01,  1.3246e+01,  7.7080e+00,  4.8810e+00],\n",
            "        [-4.7416e+00,  3.6268e+00,  1.1458e+00,  1.3348e+01,  1.9186e+00,\n",
            "         -9.2775e+00, -1.0443e+00,  1.1253e+01,  1.0524e+01,  7.4229e+00],\n",
            "        [ 3.2048e+00, -3.5934e+00, -6.2422e+00,  1.1432e+01,  3.3533e+00,\n",
            "         -1.6618e+01, -7.1437e+00,  1.0406e+01,  9.9642e+00,  5.6775e-01],\n",
            "        [-9.4816e-01,  6.4729e+00, -9.4162e+00,  1.1483e+01,  5.9305e+00,\n",
            "         -8.4252e+00,  1.3879e-01,  1.2791e+01,  4.0726e+00,  7.4990e-01],\n",
            "        [-6.4981e+00,  2.2325e+01, -1.2135e+01,  1.0662e+01,  5.3535e+00,\n",
            "         -3.6192e+00, -5.1121e+00,  5.2097e+00,  5.8325e+00,  1.7283e+00],\n",
            "        [-4.0327e+00,  7.2018e+00, -1.1452e+01,  8.3649e+00,  6.8541e-01,\n",
            "         -9.3310e+00, -1.1454e+01,  1.6127e+01,  1.8761e+00, -5.3334e+00],\n",
            "        [ 2.2910e+00,  1.3787e+01, -2.1872e+01,  1.7995e+01, -4.3996e-01,\n",
            "         -6.8751e+00, -7.3314e+00,  9.7762e+00,  7.8837e+00,  1.5605e+00],\n",
            "        [-3.7988e+00,  4.8135e+00, -1.5719e+01,  9.8440e+00,  1.0771e+01,\n",
            "         -1.3015e+00,  6.6841e-01,  5.9259e+00,  5.8895e+00,  3.1878e+00],\n",
            "        [-2.0469e+00,  2.1277e+00, -1.5095e+01,  1.5209e+01,  4.4146e-01,\n",
            "         -7.8292e+00,  8.4359e-02, -1.7239e+00,  1.3915e+00, -1.9852e+00],\n",
            "        [-2.9778e+00,  7.9326e-01, -5.3336e+00,  4.4997e+00,  6.4340e+00,\n",
            "         -1.2175e+01,  2.4173e+00,  1.8286e+01,  3.9813e-01, -9.2484e-02],\n",
            "        [ 1.1031e+01,  7.1024e+00, -1.5228e+01,  8.8945e+00,  2.6630e+00,\n",
            "         -1.4538e+01, -3.8919e+00,  8.2619e+00,  1.7066e+00, -9.1535e+00],\n",
            "        [-1.4042e+00, -2.2398e+00,  2.5800e+00,  1.4418e+01,  5.0740e+00,\n",
            "         -1.2159e+01,  1.9119e+00,  1.1239e+01,  6.5361e-01, -1.0851e+01],\n",
            "        [-3.7401e+00,  1.1277e+01, -4.4093e+00,  1.3151e+01,  2.9580e+00,\n",
            "         -9.9605e+00,  9.8945e+00,  1.3830e+01,  2.4888e+00,  2.9185e+00],\n",
            "        [ 2.1359e+00,  1.0712e+01, -9.4835e+00,  1.4765e+01,  6.9558e-01,\n",
            "         -8.4962e+00, -8.9480e+00,  9.6208e+00,  7.5285e+00,  8.4480e+00],\n",
            "        [ 4.7314e-01,  5.7658e+00, -4.4427e+00,  8.4298e+00,  6.6470e+00,\n",
            "         -1.2275e+01,  1.5418e+00,  2.4904e+01,  9.0153e+00,  5.1022e+00],\n",
            "        [ 1.3270e+01,  7.3599e+00, -5.0664e+00,  8.6035e+00, -6.3937e+00,\n",
            "         -1.1970e+01, -2.8102e+00,  1.8740e+01,  5.9849e+00, -7.7295e+00],\n",
            "        [-3.0866e+00,  8.2632e+00, -1.8717e+01,  1.4037e+01,  3.0506e+00,\n",
            "         -8.9695e+00, -2.6665e+00,  1.7697e+01,  1.1754e+01,  3.1722e+00],\n",
            "        [ 3.1519e+00,  6.1849e+00, -1.6585e+01,  1.0642e+01,  8.6934e+00,\n",
            "         -3.3917e+00, -2.1569e+00,  2.9241e+00,  2.8704e+00,  8.7597e-01],\n",
            "        [-2.0547e+00,  4.1986e+00, -5.2273e+00,  6.2041e+00,  5.8569e+00,\n",
            "         -1.5517e+01, -1.3373e+01,  1.4587e+01,  6.1238e+00, -3.2409e+00],\n",
            "        [ 6.0166e+00,  1.1279e+01, -1.9491e+01,  1.7021e+01,  1.2896e+01,\n",
            "         -9.1898e+00, -4.4646e+00,  1.4913e+01,  9.3585e+00,  6.7172e-01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDSkayC7HFRf",
        "colab_type": "text"
      },
      "source": [
        "Here's what one of the images looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OFFUBE5HFRg",
        "colab_type": "code",
        "outputId": "c255ffbe-8bcd-465f-8a7a-8e024aa79d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "plt.imshow(images[1].numpy().squeeze())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa548b25dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 253,
              "height": 250
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhxwPbrFHFRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Implement a softmax\n",
        "def softmax(x):\n",
        "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
        "\n",
        "probabilities = softmax(output)\n",
        "\n",
        "#Does it have the right shape? Should be (64, 10)\n",
        "print(probabilities.shape)\n",
        "\n",
        "#Does it sum to 1?\n",
        "print(probabilities.sum(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4IWMfU4WwsE",
        "colab_type": "text"
      },
      "source": [
        "**Building networks with PyTorch**\n",
        "\n",
        "The PyTorch model makes building networks much simpler.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdSUixJmHFRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k-i5tU6HFRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \n",
        "    \n",
        "    #Inputs to hidden layer linear transformation\n",
        "    self.hidden = nn.Linear(n_input, n_hidden)\n",
        "    \n",
        "    #Output Layer, 10 units - one for each digit\n",
        "    self.output = nn.Linear(n_hidden, n_output)\n",
        "    \n",
        "    #Define sigmoid activation and softmax output\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "      #Pass the input tensor through each of the operations\n",
        "      x = self.hidden(x)\n",
        "      x = self.sigmoid(x)\n",
        "      x = self.output(x)\n",
        "      x = self.softmax(x)\n",
        "      \n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pygadWuWHFRu",
        "colab_type": "code",
        "outputId": "ced16069-7dd9-4127-8d8c-b4815e28e6b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#Create the network and look at its text representation\n",
        "model = Classifier()\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (softmax): Softmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KYCT6dRaay8",
        "colab_type": "text"
      },
      "source": [
        "The neural network can also be written in a more cleaner and concise way using **torch.nn.functional** module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShPy-p1NHFRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \n",
        "    #Inputs to hidden layer linear transformation\n",
        "    self.hidden = nn.Linear(n_input, n_hidden)\n",
        "    \n",
        "    #Output layer, 10 units - one for each digit\n",
        "    self.output = nn.Linear(n_hidden, n_output)\n",
        "    \n",
        "    def forward(self, x):\n",
        "      #Hidden layer with sigmoid activation\n",
        "      x = F.sigmoid(self.hidden(x))\n",
        "      #Output layer with softmax activation\n",
        "      x = F.softmax(self.output(x), dim=1)\n",
        "      \n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEVk60oXHFRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#If you want non-linear out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDSrCgEOHFR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLYz8RmLaw5y",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp1GealGHFR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}