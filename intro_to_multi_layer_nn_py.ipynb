{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_to_multi_layer_nn.py.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joycechidi/Secure-and-Private-AI/blob/master/intro_to_multi_layer_nn_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFRKW2iwSgz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1V_ulh8Sg0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activation(x):\n",
        "    \"\"\"Sigmoid activation function\n",
        "    \n",
        "    Arguments\n",
        "    ----------\n",
        "    x: torch.Tensor\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    return 1/(1+torch.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWaVLlmQSg0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate some data \n",
        "torch.manual_seed(7) #Set the random seed so things are predictable\n",
        "\n",
        "#Features are 3 random normal variabes\n",
        "features = torch.randn((1, 3))\n",
        "\n",
        "#Define the size of each layer in the network\n",
        "n_input = features.shape[1] #Number of input units must match number of input features\n",
        "n_hidden = 2                #Number of hidden units\n",
        "n_output = 1                #Number of output units\n",
        "\n",
        "#Weights for inputs to hidden layer\n",
        "W1 = torch.randn(n_input, n_hidden)\n",
        "\n",
        "#Weights for inputs to hidden layer\n",
        "W2 = torch.randn(n_hidden, n_output)\n",
        "\n",
        "# and bias terms for hidden and output layers\n",
        "B1 = torch.randn(1, n_hidden)\n",
        "B2 = torch.randn(1, n_output)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNCzMb1TSg0G",
        "colab_type": "code",
        "colab": {},
        "outputId": "b0837941-24b1-40f7-81cc-26fd1a40fa33"
      },
      "source": [
        "#Calculate the output this multi-layer network\n",
        "h = activation(torch.mm(features, W1) + B1)\n",
        "output = activation(torch.mm(h, W2) + B2)\n",
        "\n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3171]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVSy-IeiSg0L",
        "colab_type": "text"
      },
      "source": [
        "# Numpy to Torch and back"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOFVxxtySg0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63Oy69JrSg0O",
        "colab_type": "code",
        "colab": {},
        "outputId": "d8ed4724-3864-41ee-9c59-538dc6cd5ace"
      },
      "source": [
        "a = np.random.rand(4, 3)\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.97272054, 0.15377103, 0.53827147],\n",
              "       [0.47678645, 0.04123979, 0.06807873],\n",
              "       [0.71509822, 0.77955059, 0.50191548],\n",
              "       [0.79362112, 0.68391943, 0.71365048]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAvS9GzDSg0S",
        "colab_type": "code",
        "colab": {},
        "outputId": "772a0a0a-66d6-4f56-e79a-c0adf6650a8c"
      },
      "source": [
        "b = torch.from_numpy(a)\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9727, 0.1538, 0.5383],\n",
              "        [0.4768, 0.0412, 0.0681],\n",
              "        [0.7151, 0.7796, 0.5019],\n",
              "        [0.7936, 0.6839, 0.7137]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SKT9alxSg0V",
        "colab_type": "code",
        "colab": {},
        "outputId": "8d94329f-7917-4c05-dba9-a4bef2dc282b"
      },
      "source": [
        "b.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.97272054, 0.15377103, 0.53827147],\n",
              "       [0.47678645, 0.04123979, 0.06807873],\n",
              "       [0.71509822, 0.77955059, 0.50191548],\n",
              "       [0.79362112, 0.68391943, 0.71365048]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmBiZe1bSg0Y",
        "colab_type": "text"
      },
      "source": [
        "Remember here that the memory is shared between the Numpy array and Torch tensor, so if you change the values in-place of one object, the other will changeas well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ56BmrBSg0Z",
        "colab_type": "text"
      },
      "source": [
        "Multiply PyTorch Tensor by 2, in place. \n",
        "This changes the value in memory. The values of the numpy array are changed by operations in the array. \n",
        "E.g Multipliction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFNu7GivSg0a",
        "colab_type": "code",
        "colab": {},
        "outputId": "6d8017c7-c182-4390-bacc-4f23f659680b"
      },
      "source": [
        "b.mul_(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.8909, 0.6151, 2.1531],\n",
              "        [1.9071, 0.1650, 0.2723],\n",
              "        [2.8604, 3.1182, 2.0077],\n",
              "        [3.1745, 2.7357, 2.8546]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDAMCL7CSg0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}